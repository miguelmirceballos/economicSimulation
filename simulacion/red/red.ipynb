{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a1603d9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0a44af1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7ae8b21f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nred_mercado.py\\n\\nEsta red neuronal está diseñada para predecir dos eventos en un mercado económico simulado:\\n1. subida_brusca_precio (subida abrupta de precios)\\n2. escasez\\n\\nCada bloque de código incluye comentarios detallados que explican su propósito y las decisiones de diseño.\\n'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "red_mercado.py\n",
    "\n",
    "Esta red neuronal está diseñada para predecir dos eventos en un mercado económico simulado:\n",
    "1. subida_brusca_precio (subida abrupta de precios)\n",
    "2. escasez\n",
    "\n",
    "Cada bloque de código incluye comentarios detallados que explican su propósito y las decisiones de diseño.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "504f895b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import classification_report, roc_auc_score, accuracy_score, precision_score, recall_score, make_scorer\n",
    "from sklearn.utils import class_weight\n",
    "from keras import Sequential, Input\n",
    "from keras.layers import Dense, Dropout, Normalization, BatchNormalization\n",
    "from scikeras.wrappers import KerasClassifier\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.optimizers import Adam, SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4333038e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Carga y preparación de datos\n",
    "# --------------------------------\n",
    "datos = pd.read_csv(\"simulacionEconomica.csv\")\n",
    "X = datos.loc[:, 'demanda_preajuste':'volatilidad_precio']\n",
    "y = datos.loc[:, 'subida_brusca_precio':'escasez']\n",
    "\n",
    "# Dividir en entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.2,\n",
    "    random_state=42\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4f2aaf58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Cálculo de pesos de clases para combatir desbalance\n",
    "# -----------------------------------------------------\n",
    "# Calculamos pesos para cada etiqueta por separado (ejemplo para subida_brusca)\n",
    "weights_subida = class_weight.compute_class_weight(\n",
    "    class_weight='balanced',\n",
    "    classes=np.unique(y_train['subida_brusca_precio']),\n",
    "    y=y_train['subida_brusca_precio']\n",
    ")\n",
    "# Mismodelaría dos etiquetas; aquí aplicaremos manualmente al fit más adelante\n",
    "class_weights = {0: weights_subida[0], 1: weights_subida[1]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7c53356b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Función para construir el modelo (para Grid Search)\n",
    "# ------------------------------------------------------\n",
    "def build_model(\n",
    "    neurons1=64,\n",
    "    neurons2=32,\n",
    "    dropout_rate=0.2,\n",
    "    learning_rate=0.001,\n",
    "    optimizer='adam'\n",
    "):\n",
    "    model = Sequential([\n",
    "        Input(shape=(5,)),\n",
    "        Normalization(),\n",
    "        Dense(neurons1, activation='relu'),\n",
    "        Dropout(dropout_rate),\n",
    "        BatchNormalization(),\n",
    "        Dense(neurons2, activation='relu'),\n",
    "        Dense(2, activation='sigmoid')\n",
    "    ])\n",
    "    # Selección de optimizador y tasa de aprendizaje\n",
    "    if optimizer == 'adam':\n",
    "        opt = Adam(learning_rate=learning_rate)\n",
    "    else:\n",
    "        opt = SGD(learning_rate=learning_rate)\n",
    "    model.compile(\n",
    "        optimizer=opt,\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=['binary_accuracy', 'Recall']\n",
    "    )\n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "aa526877",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Envolver con KerasClassifier para usar GridSearchCV\n",
    "# ------------------------------------------------------\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "\n",
    "keras_clf = KerasClassifier(model=build_model, verbose=0)\n",
    "#multi_clf = MultiOutputClassifier(keras_clf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "7477289a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2) Param grid con prefijos 'estimator__'\n",
    "param_grid = {\n",
    "    'model__neurons1':     [32, 64],\n",
    "    'model__neurons2':     [16, 32],\n",
    "    'model__dropout_rate': [0.1, 0.2],\n",
    "    'model__learning_rate':[1e-3, 1e-4],\n",
    "    'model__optimizer':    ['adam', 'sgd'],\n",
    "    'batch_size':          [64, 128],\n",
    "    'epochs':              [10, 20]\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b132383",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/miguel/miniconda3/envs/BAP3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py:548: FutureWarning: The `needs_threshold` and `needs_proba` parameter are deprecated in version 1.4 and will be removed in 1.6. You can either let `response_method` be `None` or set it to `predict` to preserve the same behaviour.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 128 candidates, totalling 384 fits\n",
      "[CV] END batch_size=64, epochs=10, model__dropout_rate=0.1, model__learning_rate=0.001, model__neurons1=32, model__neurons2=16, model__optimizer=adam; total time=   9.0s\n",
      "[CV] END batch_size=64, epochs=10, model__dropout_rate=0.1, model__learning_rate=0.001, model__neurons1=32, model__neurons2=16, model__optimizer=adam; total time=   8.9s\n",
      "[CV] END batch_size=64, epochs=10, model__dropout_rate=0.1, model__learning_rate=0.001, model__neurons1=32, model__neurons2=16, model__optimizer=adam; total time=   9.4s\n",
      "[CV] END batch_size=64, epochs=10, model__dropout_rate=0.1, model__learning_rate=0.001, model__neurons1=32, model__neurons2=16, model__optimizer=sgd; total time=   7.3s\n",
      "[CV] END batch_size=64, epochs=10, model__dropout_rate=0.1, model__learning_rate=0.001, model__neurons1=32, model__neurons2=16, model__optimizer=sgd; total time=   7.9s\n",
      "[CV] END batch_size=64, epochs=10, model__dropout_rate=0.1, model__learning_rate=0.001, model__neurons1=32, model__neurons2=16, model__optimizer=sgd; total time=   7.4s\n",
      "[CV] END batch_size=64, epochs=10, model__dropout_rate=0.1, model__learning_rate=0.001, model__neurons1=32, model__neurons2=32, model__optimizer=adam; total time=   8.7s\n",
      "[CV] END batch_size=64, epochs=10, model__dropout_rate=0.1, model__learning_rate=0.001, model__neurons1=32, model__neurons2=32, model__optimizer=adam; total time=   8.3s\n",
      "[CV] END batch_size=64, epochs=10, model__dropout_rate=0.1, model__learning_rate=0.001, model__neurons1=32, model__neurons2=32, model__optimizer=adam; total time=   8.0s\n",
      "[CV] END batch_size=64, epochs=10, model__dropout_rate=0.1, model__learning_rate=0.001, model__neurons1=32, model__neurons2=32, model__optimizer=sgd; total time=   7.4s\n",
      "[CV] END batch_size=64, epochs=10, model__dropout_rate=0.1, model__learning_rate=0.001, model__neurons1=32, model__neurons2=32, model__optimizer=sgd; total time=   7.2s\n",
      "[CV] END batch_size=64, epochs=10, model__dropout_rate=0.1, model__learning_rate=0.001, model__neurons1=32, model__neurons2=32, model__optimizer=sgd; total time=   7.2s\n",
      "[CV] END batch_size=64, epochs=10, model__dropout_rate=0.1, model__learning_rate=0.001, model__neurons1=64, model__neurons2=16, model__optimizer=adam; total time=   8.4s\n",
      "[CV] END batch_size=64, epochs=10, model__dropout_rate=0.1, model__learning_rate=0.001, model__neurons1=64, model__neurons2=16, model__optimizer=adam; total time=   8.4s\n",
      "[CV] END batch_size=64, epochs=10, model__dropout_rate=0.1, model__learning_rate=0.001, model__neurons1=64, model__neurons2=16, model__optimizer=adam; total time=   8.0s\n",
      "[CV] END batch_size=64, epochs=10, model__dropout_rate=0.1, model__learning_rate=0.001, model__neurons1=64, model__neurons2=16, model__optimizer=sgd; total time=   7.3s\n",
      "[CV] END batch_size=64, epochs=10, model__dropout_rate=0.1, model__learning_rate=0.001, model__neurons1=64, model__neurons2=16, model__optimizer=sgd; total time=   7.3s\n",
      "[CV] END batch_size=64, epochs=10, model__dropout_rate=0.1, model__learning_rate=0.001, model__neurons1=64, model__neurons2=16, model__optimizer=sgd; total time=   7.3s\n",
      "[CV] END batch_size=64, epochs=10, model__dropout_rate=0.1, model__learning_rate=0.001, model__neurons1=64, model__neurons2=32, model__optimizer=adam; total time=   8.4s\n",
      "[CV] END batch_size=64, epochs=10, model__dropout_rate=0.1, model__learning_rate=0.001, model__neurons1=64, model__neurons2=32, model__optimizer=adam; total time=   8.3s\n",
      "[CV] END batch_size=64, epochs=10, model__dropout_rate=0.1, model__learning_rate=0.001, model__neurons1=64, model__neurons2=32, model__optimizer=adam; total time=   8.1s\n",
      "[CV] END batch_size=64, epochs=10, model__dropout_rate=0.1, model__learning_rate=0.001, model__neurons1=64, model__neurons2=32, model__optimizer=sgd; total time=   7.6s\n",
      "[CV] END batch_size=64, epochs=10, model__dropout_rate=0.1, model__learning_rate=0.001, model__neurons1=64, model__neurons2=32, model__optimizer=sgd; total time=   7.5s\n",
      "[CV] END batch_size=64, epochs=10, model__dropout_rate=0.1, model__learning_rate=0.001, model__neurons1=64, model__neurons2=32, model__optimizer=sgd; total time=   7.0s\n",
      "[CV] END batch_size=64, epochs=10, model__dropout_rate=0.1, model__learning_rate=0.0001, model__neurons1=32, model__neurons2=16, model__optimizer=adam; total time=   8.5s\n",
      "[CV] END batch_size=64, epochs=10, model__dropout_rate=0.1, model__learning_rate=0.0001, model__neurons1=32, model__neurons2=16, model__optimizer=adam; total time=   7.6s\n",
      "[CV] END batch_size=64, epochs=10, model__dropout_rate=0.1, model__learning_rate=0.0001, model__neurons1=32, model__neurons2=16, model__optimizer=adam; total time=   7.5s\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Input, Dense, Dropout, BatchNormalization, Normalization\n",
    "from keras.optimizers import Adam, SGD\n",
    "from keras.callbacks import EarlyStopping\n",
    "from scikeras.wrappers import KerasClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.metrics import roc_auc_score, make_scorer\n",
    "\n",
    "# 1. Carga y partición de datos\n",
    "datos = pd.read_csv(\"simulacionEconomica.csv\")\n",
    "X = datos.loc[:, 'demanda_preajuste':'volatilidad_precio']\n",
    "y = datos.loc[:, 'subida_brusca_precio':'escasez']\n",
    "\n",
    "X_train, X_test, y_train_df, y_test_df = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# 2. Definición del modelo (salida única)\n",
    "def build_model(neurons1=64,\n",
    "                neurons2=32,\n",
    "                dropout_rate=0.2,\n",
    "                learning_rate=1e-3,\n",
    "                optimizer='adam'):\n",
    "    model = Sequential([\n",
    "        Input(shape=(X_train.shape[1],)),\n",
    "        Normalization(),\n",
    "        Dense(neurons1, activation='relu'),\n",
    "        Dropout(dropout_rate),\n",
    "        BatchNormalization(),\n",
    "        Dense(neurons2, activation='relu'),\n",
    "        Dropout(dropout_rate),\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    opt = Adam(learning_rate) if optimizer=='adam' else SGD(learning_rate)\n",
    "    model.compile(\n",
    "        optimizer=opt,\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=['AUC']\n",
    "    )\n",
    "    return model\n",
    "\n",
    "# 3. Parámetros de búsqueda comunes\n",
    "param_grid_justificada = {\n",
    "    'model__neurons1': [32, 64],           # Capa oculta principal pequeña y mediana\n",
    "    'model__dropout_rate': [0.2],     # Dropout bajo y moderado\n",
    "    'model__learning_rate': [1e-3, 1e-4],  # Learning rates comunes en DL\n",
    "    'model__optimizer': ['adam'],           # Optimización adaptativa confiable\n",
    "    'batch_size': [64],                     # Tamaño estándar para batch\n",
    "    'epochs': [15]                         # Número de épocas razonable para ver tendencia\n",
    "}\n",
    "\n",
    "# 4. Función para ejecutar una búsqueda por etiqueta\n",
    "def run_grid_search(label_name):\n",
    "    # 4.1 pesos de clase\n",
    "    w = class_weight.compute_class_weight(\n",
    "        class_weight='balanced',\n",
    "        classes=np.unique(y_train_df[label_name]),\n",
    "        y=y_train_df[label_name]\n",
    "    )\n",
    "    cw = {0: w[0], 1: w[1]}\n",
    "\n",
    "    # 4.2 definir wrapper\n",
    "    clf = KerasClassifier(\n",
    "        model=build_model,\n",
    "        verbose=0\n",
    "    )\n",
    "\n",
    "    # 4.3 GridSearchCV con AUC binario\n",
    "    auc_scorer = make_scorer(roc_auc_score, needs_proba=True)\n",
    "    es = EarlyStopping(monitor='val_auc', mode='max', patience=3, restore_best_weights=True)\n",
    "    grid = GridSearchCV(\n",
    "        estimator=clf,\n",
    "        param_grid=param_grid,\n",
    "        scoring=auc_scorer,\n",
    "        cv=2,\n",
    "        verbose=2,\n",
    "        error_score='raise'\n",
    "    )\n",
    "\n",
    "    # 4.4 fit sobre la columna correspondiente\n",
    "    grid.fit(\n",
    "        X_train,\n",
    "        y_train_df[label_name],\n",
    "        validation_split=0.2,\n",
    "        callbacks=[es],\n",
    "        class_weight=cw\n",
    "    )\n",
    "    return grid\n",
    "\n",
    "# 5. Ejecutar ambas búsquedas\n",
    "grid_subida = run_grid_search('subida_brusca_precio')\n",
    "grid_escasez = run_grid_search('escasez')\n",
    "\n",
    "# 6. Extraer cv_results_ y formar DataFrames\n",
    "df1 = pd.DataFrame(grid_subida.cv_results_)\n",
    "df2 = pd.DataFrame(grid_escasez.cv_results_)\n",
    "\n",
    "# 7. Filtrar columnas de interés\n",
    "params = [c for c in df1.columns if c.startswith('param_')]\n",
    "df1 = df1[params + ['mean_test_score']].rename(\n",
    "    columns={'mean_test_score':'score_subida'}\n",
    ")\n",
    "df2 = df2[params + ['mean_test_score']].rename(\n",
    "    columns={'mean_test_score':'score_escasez'}\n",
    ")\n",
    "\n",
    "# 8. Merge y cálculo de score combinado\n",
    "df = pd.merge(df1, df2, on=params)\n",
    "df['mean_score'] = (df['score_subida'] + df['score_escasez']) / 2\n",
    "\n",
    "# 9. Seleccionar el mejor\n",
    "best_row = df.sort_values('mean_score', ascending=False).iloc[0]\n",
    "best_params = {k.replace('param_', ''): best_row[k] for k in params}\n",
    "best_mean_score = best_row['mean_score']\n",
    "\n",
    "print(\"Mejores hiperparámetros combinados:\")\n",
    "for k, v in best_params.items():\n",
    "    print(f\"  • {k}: {v}\")\n",
    "print(f\"Score medio AUC: {best_mean_score:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bd7b16a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "143e55d5",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'grid_result' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# 7. Resultados de la búsqueda\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m best_params \u001b[38;5;241m=\u001b[39m \u001b[43mgrid_result\u001b[49m\u001b[38;5;241m.\u001b[39mbest_params_\n\u001b[1;32m      3\u001b[0m best_score \u001b[38;5;241m=\u001b[39m grid_result\u001b[38;5;241m.\u001b[39mbest_score_\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMejores hiperparámetros:\u001b[39m\u001b[38;5;124m\"\u001b[39m, best_params)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'grid_result' is not defined"
     ]
    }
   ],
   "source": [
    "# 7. Resultados de la búsqueda\n",
    "best_params = grid_result.best_params_\n",
    "best_score = grid_result.best_score_\n",
    "print(\"Mejores hiperparámetros:\", best_params)\n",
    "print(f\"Mejor AUC en validación: {best_score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1fb4ce8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "Accuracy (macro): 0.7626\n",
      "Precision (macro): 0.8494\n",
      "Recall (macro): 0.7718\n",
      "ROC AUC (macro): 0.9302\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "subida_brusca       0.77      0.65      0.71      2833\n",
      "      escasez       0.92      0.89      0.91      1164\n",
      "\n",
      "    micro avg       0.82      0.72      0.77      3997\n",
      "    macro avg       0.85      0.77      0.81      3997\n",
      " weighted avg       0.82      0.72      0.77      3997\n",
      "  samples avg       0.26      0.26      0.26      3997\n",
      "\n",
      "Matriz de confusión — subida brusca:\n",
      "[[3629  538]\n",
      " [ 984 1849]]\n",
      "\n",
      "Matriz de confusión — escasez:\n",
      "[[5751   85]\n",
      " [ 127 1037]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/miguel/miniconda3/envs/BAP3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/miguel/miniconda3/envs/BAP3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/miguel/miniconda3/envs/BAP3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in samples with no true nor predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# 8. Evaluación final con el mejor modelo\n",
    "# ---------------------------------------\n",
    "best_model = grid_result.best_estimator_.model\n",
    "\n",
    "y_pred_prob = best_model.predict(X_test)\n",
    "y_pred = (y_pred_prob >= 0.5).astype(int)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, average='macro', zero_division=0)\n",
    "recall = recall_score(y_test, y_pred, average='macro', zero_division=0)\n",
    "roc_auc = roc_auc_score(y_test, y_pred_prob, average='macro')\n",
    "\n",
    "print(f\"\\nEvaluación en test:\")\n",
    "print(f\"Precision global: {accuracy:.4f}\")\n",
    "print(f\"Precision macro: {precision:.4f}\")\n",
    "print(f\"Recall macro: {recall:.4f}\")\n",
    "print(f\"ROC AUC macro: {roc_auc:.4f}\")\n",
    "\n",
    "# Reporte detallado\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred, target_names=['subida_brusca','escasez']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45b8b493",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
      "\n",
      "Predicciones de ejemplo:\n",
      " demanda_preajuste  volatilidad_precio  prob_subida_brusca  prob_escasez  pred_subida_brusca  pred_escasez\n",
      "            2427.0             1.34536            0.726713      0.122132                True         False\n",
      "            2487.0             1.46544            0.389270      0.015678               False         False\n",
      "            2519.0             1.53623            0.471926      0.020069               False         False\n",
      "            2528.0             1.56445            0.285196      0.006426               False         False\n",
      "            2617.0             1.63936            0.411950      0.013952               False         False\n",
      "            2688.0             1.82962            0.716722      0.088721                True         False\n",
      "            2676.0             2.00250            0.722453      0.058455                True         False\n",
      "            2693.0             2.01184            0.166892      0.001146               False         False\n",
      "            2852.0             1.97231            0.168881      0.000920               False         False\n",
      "            2861.0             2.04634            0.816546      0.133766                True         False\n"
     ]
    }
   ],
   "source": [
    "# 9. Predicciones de ejemplo con el mejor modelo\n",
    "# ---------------------------------------------\n",
    "muestra = datos.iloc[1510:1520]\n",
    "prob_muestra = best_model.predict(muestra.loc[:, 'demanda_preajuste':'volatilidad_precio'])\n",
    "pred_muestra = (prob_muestra >= 0.5).astype(int)\n",
    "\n",
    "df_pred = pd.DataFrame({\n",
    "    'demanda_preajuste': muestra.demanda_preajuste,\n",
    "    'volatilidad_precio': muestra.volatilidad_precio,\n",
    "    'prob_subida_brusca': prob_muestra[:, 0],\n",
    "    'prob_escasez': prob_muestra[:, 1],\n",
    "    'pred_subida_brusca': pred_muestra[:, 0],\n",
    "    'pred_escasez': pred_muestra[:, 1]\n",
    "})\n",
    "print(\"\\nPredicciones de ejemplo:\")\n",
    "print(df_pred.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2493cdfd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BAP3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
